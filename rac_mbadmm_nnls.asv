%% RAC - MBADMM - non negative least squares
% MSE 310 Linear Programming
% project 3
% Stephen Palmieri


%% RAC
clear all;close all;clc;
n = 10;
p = 20;
% n = 100;
% p = 200;
blocks = 5;
rng(5)
y = sprandn(n,1,.1);
X = sprandn(n,p,.1);
beta_true = pos(sprandn(p,1,.1));
y = X*beta_true;
beta0 = pos(sprandn(p,1,.1));
z0 = pos(sprandn(p,1,.1));
mu0 = pos(sprandn(p,1,.1));
k = 1;
err(k) = norm(beta_true-beta0,2);
err_bz(k) = norm(beta0-z0,2);
toler = 1e-4;
maxIter = 1000;
gammas = [.1, 1, 10,1000];

for jj = 1:length(gammas)
    for ii = 1:maxIter
        
        [beta_out,z_out,mu_out] = rac_nnls(y,X,beta0,z0, mu0, blocks,gammas(jj));
        beta0 = beta_out;
        z0 = z_out;
        mu0 = mu_out;
        beta(:,k) = beta_out;
        z(:,k,jj) = z_out;
        mu(:,k,jj) = mu_out;
        obj(k,jj) = 1/(2*n) * (y-X*beta_out)'*(y-X*beta_out);
        obj_al(k,jj) = obj(k,jj) + gamma/2*norm(beta_out-z_out,2)^2 - mu_out'*(beta_out-z_out);
        k = k+1;
        
        % err(k) = norm(beta_out-z_out,2);
        err(k,jj) = norm(beta_true-beta_out,2);
        err_bz(k,jj) = norm(beta_out-z_out,2);
        % if abs(err(k)-err(k-1))  < toler
        if err(k,jj) < toler
            disp('below tolerance')
            break
        else
        end
        
    end
end

for iii = 1:length(gammas)
    figure
    plot(err(:,jj))
    hold on
    xlabel('iterations')
    ylabel('error')
    title('l-2 norm \beta error from true value')
end
legend('.1','1','10','1000')

for iii = 1:length(gammas)
    figure
    plot(err_bz(:,jj))
    hold on
    xlabel('iterations')
    ylabel('error')
    title('l-2 norm (\beta - z) error')
end
legend('.1','1','10','1000')

for iii = 1:length(gammas)
    figure
    plot(obj(:,jj))
    hold on
%     plot(obj_al)
%     legend('original obj','augmented Lagrangian')
    xlabel('iterations')
    ylabel('objective loss')
    title('Non-negative Least Squares Objective Loss vs Iterations using RAC-MBADMM')
end
legend('.1','1','10','1000')

%% Randomly Permute Comparison - Section IV
clear all;close all;clc;
n = 100;
p = 200;
blocks = p;

rng(5)
y = sprandn(n,1,.1);
X = sprandn(n,p,.1);

beta_true = pos(sprandn(p,1,.1));
y = X*beta_true;

beta0 = pos(sprandn(p,1,.1));
z0 = pos(sprandn(p,1,.1));
mu0 = pos(sprandn(p,1,.1));
gammas = [.1, 1, 10,1000];

k = 1;
err(k) = norm(beta_true-beta0,2);
err_bz(k) = norm(beta0-z0,2);
toler = 1e-3;
maxIter = 1000;

%loop through different regularization parameterization
for jj = 1:length(gammas)
    for ii = 1:maxIter
        
        [beta_out,z_out,mu_out] = rp_nnls(y,X,beta0,z0, mu0, blocks, gammas(jj));
        beta0 = beta_out;
        z0 = z_out;
        mu0 = mu_out;
        beta(:,k) = beta_out;
        z(:,k) = z_out;
        mu(:,k) = mu_out;
        obj(k) = 1/(2*n) * (y-X*beta_out)'*(y-X*beta_out);
        obj_al(k) = obj(k) + gamma/2*norm(beta_out-z_out,2)^2 - mu_out'*(beta_out-z_out);
        k = k+1;
        err(k) = norm(beta_true-beta_out,2);
        err_bz(k) = norm(beta_out-z_out,2);
        if err(k) <toler
            disp('below tolerance')
            break
        else
        end
    end
    
end

%% plotting
figure
plot(1:k,err)
xlabel('iterations')
ylabel('error')
title('l-2 norm \beta error from true value')

figure
plot(1:k,err_bz)
xlabel('iterations')
ylabel('error')
title('l-2 norm (\beta - z) error')

figure
plot(obj)
hold on
plot(obj_al)
legend('original obj','augmented Lagrangian')
xlabel('iterations')
ylabel('objective loss')
title('Non-negative Least Squares Objective Loss vs Iterations using RP-MBADMM')

